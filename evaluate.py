import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# --- 1. C·∫§U H√åNH ---
DATA_FILE = 'data_onkk.csv'
MODEL_DIR = 'models'
SPLIT_DIR = 'splits'
TEST_DATE_FILE = 'test_dates.txt'

# --- C·∫§U H√åNH 5 L·ªöP ---
TARGET_NAMES = ["T·ªët (0-50)", "TB (51-100)", "K√©m (101-150)", "X·∫•u (151-200)", "R·∫•t x·∫•u (>200)"]
TARGET_LABELS = [0, 1, 2, 3, 4]

# H√†m ƒë·ªçc ng√†y t·ª´ file txt
def load_dates_from_file(filename):
    path = os.path.join(SPLIT_DIR, filename)
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y file {path}. S·∫Ω d·ª´ng ƒë√°nh gi√°.")
        return []
    with open(path, 'r') as f:
        dates = [line.strip() for line in f if line.strip()]
    return dates

# --- 2. C√îNG TH·ª®C T√çNH AQI CHU·∫®N VI·ªÜT NAM (GI·ªÆ NGUY√äN) ---
def calculate_aqi(pm25):
    """T√≠nh ch·ªâ s·ªë AQI ch√≠nh x√°c theo c√¥ng th·ª©c"""
    # B·∫£ng 1: Quy ƒë·ªãnh gi√° tr·ªã BP v√† I 
    breakpoints = [
        (0, 25, 0, 50), (25, 50, 50, 100), (50, 80, 100, 150), 
        (80, 150, 150, 200), (150, 250, 200, 300), 
        (250, 350, 300, 400), (350, 500, 400, 500)
    ]
    Cx = float(pm25) 
    if Cx < 0: return 0
    if Cx > 500: return 500 
    
    for bp in breakpoints:
        BP_lo, BP_hi, I_lo, I_hi = bp
        if BP_lo <= Cx <= BP_hi:
            tu_so = I_hi - I_lo
            mau_so = BP_hi - BP_lo
            hieu_so = Cx - BP_lo
            aqi = (tu_so / mau_so) * hieu_so + I_lo
            return aqi
    return 0

def get_aqi_category_from_index(aqi_val):
    if aqi_val <= 50: return 0 
    elif aqi_val <= 100: return 1
    elif aqi_val <= 150: return 2
    elif aqi_val <= 200: return 3
    else: return 4

def pm25_to_label_final(pm25):
    aqi_index = calculate_aqi(pm25)
    return get_aqi_category_from_index(aqi_index)

# --- 3. CHU·∫®N B·ªä V√Ä L·ªåC D·ªÆ LI·ªÜU ---
print("ƒêang ƒë·ªçc d·ªØ li·ªáu...")
df = pd.read_csv(DATA_FILE)
df['time'] = pd.to_datetime(df['time'])

# Load danh s√°ch ng√†y Test
test_dates_list = load_dates_from_file(TEST_DATE_FILE)
if not test_dates_list:
    exit()

test_dt = pd.to_datetime(test_dates_list)

# L·ªçc: Ch·ªâ gi·ªØ l·∫°i c√°c d√≤ng thu·ªôc ng√†y Test
eval_df = df[df['time'].isin(test_dt)].copy()

if len(eval_df) == 0:
    print(f"‚ùå L·ªñI: Kh√¥ng t√¨m th·∫•y m·∫´u d·ªØ li·ªáu n√†o trong file {DATA_FILE} kh·ªõp v·ªõi ng√†y trong {TEST_DATE_FILE}.")
    exit()

# L∆ØU √ù: N·∫øu b·∫°n ƒë√£ th√™m Feature Engineering (nh∆∞ Stagnation/DewPoint) ·ªü file train, 
# B·∫†N C≈®NG C·∫¶N TH√äM V√ÄO ƒê√ÇY tr∆∞·ªõc khi ƒë·ªãnh nghƒ©a features.
# V√≠ d·ª•: eval_df['Stagnation'] = 1 / (eval_df['WSPD'] + 0.1)

features = ['PRES2M', 'RH', 'WSPD', 'TMP', 'TP', 'SQRT_SEA_DEM_LAT'] 
X_test = eval_df[features]

# T·∫†O NH√ÉN TH·∫¨T (GROUND TRUTH)
print(f"ƒêang t√≠nh to√°n nh√£n th·ª±c t·∫ø t·ª´ s·ªë li·ªáu tr·∫°m ({len(eval_df)} m·∫´u Test)...")
y_true = eval_df['pm25'].apply(pm25_to_label_final).values

# 4. ƒê√ÅNH GI√Å MODEL
models_to_test = ['rf_reg_phys.pkl', 'xgb_reg_phys.pkl'] # T√™n model sau khi t·ªëi ∆∞u

print(f"\n{'='*10} B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å TR√äN T·∫¨P TEST ƒê·ªòC L·∫¨P {'='*10}")

for model_name in models_to_test:
    model_path = os.path.join(MODEL_DIR, model_name)
    
    # Ki·ªÉm tra c√°c phi√™n b·∫£n model c≈© n·∫øu kh√¥ng t√¨m th·∫•y t√™n model m·ªõi
    if not os.path.exists(model_path):
        model_name = model_name.replace('_phys', '')
        model_path = os.path.join(MODEL_DIR, model_name)
        
    if not os.path.exists(model_path):
        print(f"Kh√¥ng t√¨m th·∫•y file: {model_name}")
        continue
        
    print(f"\nüîç ƒêang ƒë√°nh gi√°: {model_name}...")
    model = joblib.load(model_path)
    
    # A. D·ª± b√°o ra n·ªìng ƒë·ªô PM2.5 (S·ªë th·ª±c)
    y_pred_pm25 = model.predict(X_test)
    
    # B. T√≠nh AQI t·ª´ PM2.5 d·ª± b√°o -> Quy ra nh√£n
    y_pred_class = [pm25_to_label_final(val) for val in y_pred_pm25]
    
    # --- T√çNH TO√ÅN CH·ªà S·ªê ---
    acc = accuracy_score(y_true, y_pred_class)
    print(f"ƒê·ªô ch√≠nh x√°c ph√¢n l·ªõp (Accuracy): {acc:.2%}")
    
    print("\nCLASSIFICATION REPORT:")
    print(classification_report(
        y_true, 
        y_pred_class, 
        labels=TARGET_LABELS,      
        target_names=TARGET_NAMES,  
        zero_division=0
    ))
    
    # V·∫º CONFUSION MATRIX
    cm = confusion_matrix(y_true, y_pred_class, labels=TARGET_LABELS)
    
    plt.figure(figsize=(10, 7))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=TARGET_NAMES, 
                yticklabels=TARGET_NAMES)
    plt.xlabel('D·ª± b√°o (Predicted)')
    plt.ylabel('Th·ª±c t·∫ø (Actual)')
    plt.title(f'Confusion Matrix - {model_name}\n')
    plt.show()
    
    print("-" * 50)